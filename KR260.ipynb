{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from pynq_dpu import DpuOverlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"img/jinrikisha-911722.JPEG\"\n",
    "MODEL_PATH = \"/home/ubuntu/Kria-PYNQ/movenet_kr260_vai25.xmodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5245c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_R_MEAN = 123.68\n",
    "_G_MEAN = 116.78\n",
    "_B_MEAN = 103.94\n",
    "\n",
    "MEANS = [_B_MEAN,_G_MEAN,_R_MEAN]\n",
    "\n",
    "def resize_shortest_edge(image, size):\n",
    "    H, W = image.shape[:2]\n",
    "    if H >= W:\n",
    "        nW = size\n",
    "        nH = int(float(H)/W * size)\n",
    "    else:\n",
    "        nH = size\n",
    "        nW = int(float(W)/H * size)\n",
    "    return cv2.resize(image,(nW,nH))\n",
    "\n",
    "def mean_image_subtraction(image, means):\n",
    "    B, G, R = cv2.split(image)\n",
    "    B = B - means[0]\n",
    "    G = G - means[1]\n",
    "    R = R - means[2]\n",
    "    image = cv2.merge([R, G, B])\n",
    "    return image\n",
    "\n",
    "def BGR2RGB(image):\n",
    "    B, G, R = cv2.split(image)\n",
    "    image = cv2.merge([R, G, B])\n",
    "    return image\n",
    "\n",
    "def central_crop(image, crop_height, crop_width):\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    offset_height = (image_height - crop_height) // 2\n",
    "    offset_width = (image_width - crop_width) // 2\n",
    "    return image[offset_height:offset_height + crop_height, offset_width:\n",
    "                 offset_width + crop_width, :]\n",
    "\n",
    "def normalize(image):\n",
    "    image=image/256.0\n",
    "    image=image-0.5\n",
    "    image=image*2\n",
    "    return image\n",
    "\n",
    "def preprocess_fn(image, crop_height = 192, crop_width = 192):\n",
    "    image = resize_shortest_edge(image, 256)\n",
    "    image = mean_image_subtraction(image, MEANS)\n",
    "    image = central_crop(image, crop_height, crop_width)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa719b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading DPU Overlay and Model: {MODEL_PATH}...\")\n",
    "overlay = DpuOverlay(\"dpu.bit\")\n",
    "overlay.load_model(MODEL_PATH)\n",
    "dpu_runner = overlay.runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf888a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTensors = dpu_runner.get_input_tensors()\n",
    "outputTensors = dpu_runner.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)\n",
    "\n",
    "print(f\" Model Loaded!\")\n",
    "print(f\"   Input Tensor : {shapeIn} ({inputTensors[0].dtype})\")\n",
    "print(f\"   Output Tensor: {shapeOut} ({outputTensors[0].dtype})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = [np.empty(shapeOut, dtype=np.int8, order=\"C\")]\n",
    "input_data = [np.empty(shapeIn, dtype=np.int8, order=\"C\")]\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbedc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 2. PRE-PROCESSING\n",
    "# ----------------------------------------\n",
    "print(f\"Loading {IMAGE_PATH}...\")\n",
    "img = preprocess_fn(cv2.imread(IMAGE_PATH))\n",
    "if img is None:\n",
    "    print(\"Error: Could not load image. Check filename.\")\n",
    "    exit()\n",
    "\n",
    "# Resize to what the model expects\n",
    "input_height, input_width = shapeIn[1], shapeIn[2]\n",
    "resized_img = cv2.resize(img, (input_width, input_height))\n",
    "\n",
    "# Prepare the Input Buffer\n",
    "# Vitis AI DPU expects data in the buffer we allocate\n",
    "input_data = [np.empty(shapeIn, dtype=np.int8, order=\"C\")]\n",
    "output_data = [np.empty(shapeOut, dtype=np.int8, order=\"C\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c345451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# 3. INFERENCE (FPGA TIME!)\n",
    "# ----------------------------------------\n",
    "print(\"Running DPU Execution...\")\n",
    "start_t = time.time()\n",
    "\n",
    "image[0,...] = img.reshape(shapeIn[1:])\n",
    "job_id = dpu_runner.execute_async(input_data, output_data)\n",
    "dpu_runner.wait(job_id)\n",
    "\n",
    "end_t = time.time()\n",
    "print(f\"Inference Time: {(end_t - start_t)*1000:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
